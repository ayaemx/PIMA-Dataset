{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PIMA Indians Diabetes Prediction - Complete ML Pipeline\n",
    "\n",
    "**Objective:** Build a comprehensive diabetes prediction system achieving >90% accuracy\n",
    "\n",
    "**Models:** Logistic Regression, Random Forest, SVM, KNN, Decision Tree, Gradient Boosting, XGBoost, Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q xgboost imbalanced-learn\n",
    "\n",
    "# Core imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ML imports\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import xgboost as xgb\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load PIMA dataset\n",
    "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
    "columns = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', \n",
    "           'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome']\n",
    "\n",
    "df = pd.read_csv(url, names=columns)\n",
    "print(f\"Dataset loaded: {df.shape}\")\n",
    "print(f\"Target distribution:\\n{df['Outcome'].value_counts()}\")\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA - Target distribution\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "df['Outcome'].value_counts().plot(kind='bar', ax=ax1, color=['skyblue', 'lightcoral'])\n",
    "ax1.set_title('Target Distribution')\n",
    "ax1.set_xticklabels(['No Diabetes', 'Diabetes'], rotation=0)\n",
    "\n",
    "# Correlation with target\n",
    "corr = df.corr()['Outcome'].abs().sort_values(ascending=False)[1:]\n",
    "corr.plot(kind='bar', ax=ax2, color='steelblue')\n",
    "ax2.set_title('Feature Correlation with Target')\n",
    "ax2.tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Top correlated features:\")\n",
    "for feature, corr_val in corr.head().items():\n",
    "    print(f\"- {feature}: {corr_val:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing\n",
    "print(\"Preprocessing data...\")\n",
    "\n",
    "# Handle missing values (zeros are biologically impossible)\n",
    "df_processed = df.copy()\n",
    "zero_cols = ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']\n",
    "for col in zero_cols:\n",
    "    df_processed[col] = df_processed[col].replace(0, np.nan)\n",
    "\n",
    "# Separate features and target\n",
    "X = df_processed.drop('Outcome', axis=1)\n",
    "y = df_processed['Outcome']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Impute missing values\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "X_train_imputed = pd.DataFrame(imputer.fit_transform(X_train), columns=X.columns)\n",
    "X_test_imputed = pd.DataFrame(imputer.transform(X_test), columns=X.columns)\n",
    "\n",
    "# Feature engineering\n",
    "for data in [X_train_imputed, X_test_imputed]:\n",
    "    data['BMI_Category'] = pd.cut(data['BMI'], bins=[0, 25, 30, float('inf')], labels=[0, 1, 2])\n",
    "    data['Age_Group'] = pd.cut(data['Age'], bins=[0, 30, 50, float('inf')], labels=[0, 1, 2])\n",
    "    data['Glucose_Category'] = pd.cut(data['Glucose'], bins=[0, 100, 126, float('inf')], labels=[0, 1, 2])\n",
    "    data['BMI_Age_Interaction'] = data['BMI'] * data['Age'] / 100\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_imputed)\n",
    "X_test_scaled = scaler.transform(X_test_imputed)\n",
    "\n",
    "# Apply SMOTE for class balancing\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_balanced, y_train_balanced = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "print(f\"Training samples after balancing: {len(X_train_balanced)}\")\n",
    "print(f\"Test samples: {len(X_test_scaled)}\")\n",
    "print(f\"Features: {X_train_imputed.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train 8 ML models\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'SVM': SVC(probability=True, random_state=42),\n",
    "    'KNN': KNeighborsClassifier(n_neighbors=5),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=42, max_depth=10),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(random_state=42),\n",
    "    'XGBoost': xgb.XGBClassifier(random_state=42, eval_metric='logloss'),\n",
    "    'Neural Network': MLPClassifier(hidden_layer_sizes=(100, 50), random_state=42, max_iter=500)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "print(\"Training models...\")\n",
    "for name, model in models.items():\n",
    "    # Train model\n",
    "    model.fit(X_train_balanced, y_train_balanced)\n",
    "    \n",
    "    # Predictions\n",
    "    y_train_pred = model.predict(X_train_balanced)\n",
    "    y_test_pred = model.predict(X_test_scaled)\n",
    "    \n",
    "    # Accuracies\n",
    "    train_acc = accuracy_score(y_train_balanced, y_train_pred)\n",
    "    test_acc = accuracy_score(y_test, y_test_pred)\n",
    "    \n",
    "    # Cross-validation\n",
    "    cv_scores = cross_val_score(model, X_train_balanced, y_train_balanced, cv=5)\n",
    "    \n",
    "    results[name] = {\n",
    "        'model': model,\n",
    "        'train_acc': train_acc,\n",
    "        'test_acc': test_acc,\n",
    "        'cv_mean': cv_scores.mean(),\n",
    "        'cv_std': cv_scores.std(),\n",
    "        'overfitting': train_acc - test_acc\n",
    "    }\n",
    "    \n",
    "    print(f\"{name}: {test_acc:.4f}\")\n",
    "\n",
    "print(\"\\nTraining completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results summary\n",
    "summary_data = []\n",
    "for name, result in results.items():\n",
    "    summary_data.append({\n",
    "        'Model': name,\n",
    "        'Train Accuracy': f\"{result['train_acc']:.4f}\",\n",
    "        'Test Accuracy': f\"{result['test_acc']:.4f}\",\n",
    "        'CV Mean': f\"{result['cv_mean']:.4f}\",\n",
    "        'CV Std': f\"{result['cv_std']:.4f}\",\n",
    "        'Overfitting': f\"{result['overfitting']:.4f}\"\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "display(summary_df)\n",
    "\n",
    "# Best model\n",
    "best_model = max(results.keys(), key=lambda x: results[x]['test_acc'])\n",
    "best_acc = results[best_model]['test_acc']\n",
    "\n",
    "print(f\"\\nBest model: {best_model}\")\n",
    "print(f\"Best accuracy: {best_acc:.4f} ({best_acc*100:.2f}%)\")\n",
    "\n",
    "if best_acc > 0.90:\n",
    "    print(\"TARGET ACHIEVED: >90% accuracy!\")\n",
    "else:\n",
    "    print(f\"Target not reached. Best: {best_acc*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance visualization\n",
    "model_names = list(results.keys())\n",
    "test_accs = [results[model]['test_acc'] for model in model_names]\n",
    "train_accs = [results[model]['train_acc'] for model in model_names]\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Performance comparison\n",
    "x = np.arange(len(model_names))\n",
    "width = 0.35\n",
    "\n",
    "ax1.bar(x - width/2, train_accs, width, label='Training', alpha=0.8)\n",
    "ax1.bar(x + width/2, test_accs, width, label='Testing', alpha=0.8)\n",
    "ax1.axhline(y=0.90, color='red', linestyle='--', label='90% Target')\n",
    "ax1.set_xlabel('Models')\n",
    "ax1.set_ylabel('Accuracy')\n",
    "ax1.set_title('Model Performance Comparison')\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels(model_names, rotation=45, ha='right')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Overfitting analysis\n",
    "overfitting = [results[model]['overfitting'] for model in model_names]\n",
    "colors = ['red' if gap > 0.10 else 'orange' if gap > 0.05 else 'green' for gap in overfitting]\n",
    "\n",
    "ax2.bar(model_names, overfitting, color=colors, alpha=0.7)\n",
    "ax2.set_title('Overfitting Analysis (Train - Test Accuracy)')\n",
    "ax2.set_ylabel('Overfitting Gap')\n",
    "ax2.tick_params(axis='x', rotation=45)\n",
    "ax2.axhline(y=0.05, color='orange', linestyle='--', alpha=0.7)\n",
    "ax2.axhline(y=0.10, color='red', linestyle='--', alpha=0.7)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrices for top 4 models\n",
    "sorted_models = sorted(results.items(), key=lambda x: x[1]['test_acc'], reverse=True)\n",
    "top_4 = dict(sorted_models[:4])\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i, (name, result) in enumerate(top_4.items()):\n",
    "    model = result['model']\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[i],\n",
    "                xticklabels=['No Diabetes', 'Diabetes'],\n",
    "                yticklabels=['No Diabetes', 'Diabetes'])\n",
    "    axes[i].set_title(f'{name}\\nAccuracy: {result[\"test_acc\"]:.4f}')\n",
    "    axes[i].set_ylabel('True Label')\n",
    "    axes[i].set_xlabel('Predicted Label')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter optimization for best model\n",
    "print(f\"Optimizing {best_model}...\")\n",
    "\n",
    "if best_model == 'Random Forest':\n",
    "    param_grid = {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [10, 15, 20],\n",
    "        'min_samples_split': [2, 5, 10]\n",
    "    }\n",
    "elif best_model == 'SVM':\n",
    "    param_grid = {\n",
    "        'C': [1, 10, 100],\n",
    "        'gamma': ['scale', 'auto', 0.001, 0.01]\n",
    "    }\n",
    "elif best_model == 'XGBoost':\n",
    "    param_grid = {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'learning_rate': [0.01, 0.1, 0.2],\n",
    "        'max_depth': [3, 6, 9]\n",
    "    }\n",
    "else:\n",
    "    param_grid = {}\n",
    "\n",
    "if param_grid:\n",
    "    base_model = models[best_model]\n",
    "    grid_search = GridSearchCV(base_model, param_grid, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "    grid_search.fit(X_train_balanced, y_train_balanced)\n",
    "    \n",
    "    optimized_acc = accuracy_score(y_test, grid_search.predict(X_test_scaled))\n",
    "    \n",
    "    print(f\"Original accuracy: {best_acc:.4f}\")\n",
    "    print(f\"Optimized accuracy: {optimized_acc:.4f}\")\n",
    "    print(f\"Improvement: {optimized_acc - best_acc:.4f}\")\n",
    "    print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "    \n",
    "    if optimized_acc > 0.90:\n",
    "        print(\"OPTIMIZATION SUCCESS: >90% accuracy achieved!\")\nelse:\n",
    "    print(\"No optimization parameters defined for this model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final classification report\n",
    "print(\"FINAL RESULTS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "final_model = results[best_model]['model']\n",
    "y_pred_final = final_model.predict(X_test_scaled)\n",
    "\n",
    "print(f\"Best Model: {best_model}\")\n",
    "print(f\"Test Accuracy: {best_acc:.4f} ({best_acc*100:.2f}%)\")\n",
    "print(f\"Cross-validation: {results[best_model]['cv_mean']:.4f} ± {results[best_model]['cv_std']:.4f}\")\n",
    "print(f\"Overfitting gap: {results[best_model]['overfitting']:.4f}\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_final, target_names=['No Diabetes', 'Diabetes']))\n",
    "\n",
    "# Achievement status\n",
    "models_above_90 = sum(1 for r in results.values() if r['test_acc'] > 0.90)\n",
    "print(f\"\\nModels achieving >90% accuracy: {models_above_90}/{len(results)}\")\n",
    "\n",
    "if models_above_90 > 0:\n",
    "    print(\"TARGET ACHIEVED: Multiple models reached >90% accuracy!\")\n",
    "elif best_acc > 0.85:\n",
    "    print(f\"Close to target: Best model achieved {best_acc*100:.2f}%\")\n",
    "else:\n",
    "    print(f\"Target not reached. Best: {best_acc*100:.2f}%\")\n",
    "\n",
    "print(\"\\nAnalysis completed successfully!\")"
   ]
  }
 ],\n \"metadata\": {\n  \"kernelspec\": {\n   \"display_name\": \"Python 3\",\n   \"language\": \"python\",\n   \"name\": \"python3\"\n  },\n  \"language_info\": {\n   \"codemirror_mode\": {\n    \"name\": \"ipython\",\n    \"version\": 3\n   },\n   \"file_extension\": \".py\",\n   \"mimetype\": \"text/x-python\",\n   \"name\": \"python\",\n   \"nbconvert_exporter\": \"python\",\n   \"pygments_lexer\": \"ipython3\",\n   \"version\": \"3.8.5\"\n  }\n },\n \"nbformat\": 4,\n \"nbformat_minor\": 4\n}